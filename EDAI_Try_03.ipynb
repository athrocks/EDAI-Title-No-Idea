{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pa_40nfsvNAs",
    "outputId": "93b8d976-76fa-4df8-9183-6c6c723e5531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch_geometric in ./.local/lib/python3.10/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from torch_geometric) (3.11.14)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch_geometric) (3.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.24.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2020.6.20)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOQovIGRl82b",
    "outputId": "5c74b20c-036b-4ab1-9aa6-ebd0eb2a775c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy (no training): 0.4899180156757065\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import KDTree\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------\n",
    "# Load and Prepare Data\n",
    "# ---------------------\n",
    "df = pd.read_csv(\"preprocessed_mining_data.csv\")\n",
    "\n",
    "# Define target (oil mine presence)\n",
    "# conditions = (\n",
    "#     (df['P Wave Velocity (km/s)'] < 4.5) &\n",
    "#     (df['S Wave Velocity (km/s)'] < 2.5) &\n",
    "#     (df['Carbon Emission (ppm)'] > 350) &\n",
    "#     (df['hrock_type'].isin([2, 3]))\n",
    "# )\n",
    "# df['oil_mine_presence'] = np.where(conditions, 1, 0)\n",
    "\n",
    "# Replace your original condition with this:\n",
    "conditions = (\n",
    "    (df['P Wave Velocity (km/s)'] < 5.0) &\n",
    "    (df['S Wave Velocity (km/s)'] < 3.0) &\n",
    "    (df['Carbon Emission (ppm)'] > 300) &\n",
    "    (df['hrock_type'].isin([1, 2, 3]))  # allow one more rock type\n",
    ")\n",
    "df['oil_mine_presence'] = np.where(conditions, 1, 0)\n",
    "\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = ['hrock_type', 'arock_type', 'structure', 'orebody_fm']\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "# Feature selection\n",
    "features = ['latitude', 'longitude', 'P Wave Velocity (km/s)', 'S Wave Velocity (km/s)',\n",
    "            'Humidity (%)', 'Carbon Emission (ppm)', 'hrock_type', 'arock_type',\n",
    "            'structure', 'orebody_fm']\n",
    "df_features = df[features]\n",
    "df_target = df['oil_mine_presence']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "df_features = pd.DataFrame(scaler.fit_transform(df_features), columns=features)\n",
    "nodes_np = df_features.values\n",
    "y = torch.tensor(df_target.values, dtype=torch.long)\n",
    "\n",
    "# ---------------------\n",
    "# Graph Construction\n",
    "# ---------------------\n",
    "tree = KDTree(nodes_np)\n",
    "k = 10\n",
    "distances, indices = tree.query(nodes_np, k=k)\n",
    "\n",
    "edges = []\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for j in neighbors:\n",
    "        if i != j:\n",
    "            edges.append((i, j))\n",
    "\n",
    "# Convert edges to tensor format for PyTorch\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "x = torch.tensor(nodes_np, dtype=torch.float)\n",
    "\n",
    "# ---------------------\n",
    "# Custom GAT Layer\n",
    "# ---------------------\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        self.a = nn.Parameter(torch.empty(size=(2 * out_features, 1)))\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.W.data)\n",
    "        nn.init.xavier_uniform_(self.a.data)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = torch.mm(x, self.W)  # [N, out_features]\n",
    "        row, col = edge_index\n",
    "        edge_h = torch.cat([h[row], h[col]], dim=1)  # [E, 2*out_features]\n",
    "        e = self.leakyrelu(torch.matmul(edge_h, self.a)).squeeze()  # [E]\n",
    "        alpha = F.softmax(e, dim=0)\n",
    "        alpha = self.dropout(alpha)\n",
    "        h_prime = torch.zeros_like(h)\n",
    "        h_prime.index_add_(0, row, alpha.unsqueeze(1) * h[col])\n",
    "        return F.elu(h_prime)\n",
    "\n",
    "# ---------------------\n",
    "# GAT Model\n",
    "# ---------------------\n",
    "class GATNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GATNet, self).__init__()\n",
    "        self.gat1 = GATLayer(input_dim, hidden_dim)\n",
    "        self.gat2 = GATLayer(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# ---------------------\n",
    "# Prepare Train/Test Split\n",
    "# ---------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Instantiate Model\n",
    "# ---------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GATNet(input_dim=x.shape[1], hidden_dim=8, output_dim=2).to(device)\n",
    "\n",
    "x = x.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "# Example forward pass (not training yet)\n",
    "out = model(x, edge_index)\n",
    "pred = out.argmax(dim=1)\n",
    "\n",
    "# Accuracy check\n",
    "acc = (pred == y).sum().item() / y.size(0)\n",
    "print(\"Initial Accuracy (no training):\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oil_mine_presence\n",
      "0    210772\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['oil_mine_presence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import KDTree\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --------------------- Load and Prepare Data ---------------------\n",
    "df = pd.read_csv(\"preprocessed_mining_data.csv\")\n",
    "\n",
    "# Define target (oil mine presence)\n",
    "conditions = (\n",
    "    (df['P Wave Velocity (km/s)'] < 4.5) &\n",
    "    (df['S Wave Velocity (km/s)'] < 2.5) &\n",
    "    (df['Carbon Emission (ppm)'] > 350) &\n",
    "    (df['hrock_type'].isin([2, 3]))\n",
    ")\n",
    "df['oil_mine_presence'] = np.where(conditions, 1, 0)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = ['hrock_type', 'arock_type', 'structure', 'orebody_fm']\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "# Feature selection\n",
    "features = ['latitude', 'longitude', 'P Wave Velocity (km/s)', 'S Wave Velocity (km/s)',\n",
    "            'Humidity (%)', 'Carbon Emission (ppm)', 'hrock_type', 'arock_type',\n",
    "            'structure', 'orebody_fm']\n",
    "df_features = df[features]\n",
    "df_target = df['oil_mine_presence']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "df_features = pd.DataFrame(scaler.fit_transform(df_features), columns=features)\n",
    "nodes_np = df_features.values\n",
    "y = torch.tensor(df_target.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Graph Construction ---------------------\n",
    "tree = KDTree(nodes_np)\n",
    "k = 10\n",
    "distances, indices = tree.query(nodes_np, k=k)\n",
    "\n",
    "edges = []\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for j in neighbors:\n",
    "        if i != j:\n",
    "            edges.append((i, j))\n",
    "\n",
    "# Convert edges to tensor format\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "x = torch.tensor(nodes_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 210772\n",
      "Total edges: 1896948\n",
      "Total attention computations per forward pass: 7587792\n"
     ]
    }
   ],
   "source": [
    "num_nodes = x.shape[0]\n",
    "num_edges = edge_index.shape[1]\n",
    "num_heads = 4  # your current GATNet setting\n",
    "\n",
    "print(f\"Total nodes: {num_nodes}\")\n",
    "print(f\"Total edges: {num_edges}\")\n",
    "print(f\"Total attention computations per forward pass: {num_edges * num_heads}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge density: 0.000043\n"
     ]
    }
   ],
   "source": [
    "density = num_edges / (num_nodes * (num_nodes - 1))\n",
    "print(f\"Edge density: {density:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Custom GAT Layer ---------------------\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.concat = concat\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        self.a = nn.Parameter(torch.empty(size=(2 * out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "    def forward(self, h, edge_index):\n",
    "        Wh = torch.mm(h, self.W)  # [N, out_features]\n",
    "\n",
    "        # Compute attention coefficients e_ij for each edge\n",
    "        Wh_i = Wh[edge_index[0]]  # source node features\n",
    "        Wh_j = Wh[edge_index[1]]  # target node features\n",
    "        edge_input = torch.cat([Wh_i, Wh_j], dim=1)  # [E, 2*out_features]\n",
    "\n",
    "        e = self.leakyrelu(torch.matmul(edge_input, self.a).squeeze(-1))  # [E]\n",
    "\n",
    "        # Normalize coefficients per source node using softmax\n",
    "        e = F.dropout(e, self.dropout, training=self.training)\n",
    "        # alpha = F.softmax(e, index=edge_index[0], dim=0)  # ⬅️ normalize per source node\n",
    "        alpha = softmax(e, edge_index[0])\n",
    "\n",
    "        # Message passing: weighted sum of Wh_j using alpha\n",
    "        h_prime = torch.zeros_like(Wh)\n",
    "        h_prime = h_prime.index_add(0, edge_index[0], alpha.unsqueeze(1) * Wh_j)\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- GAT Model ---------------------\n",
    "class GATNet(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, dropout=0.6, alpha=0.2, heads=4):\n",
    "        super(GATNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.attentions = nn.ModuleList([\n",
    "            GATLayer(in_features, hidden_features, dropout=dropout, alpha=alpha, concat=True)\n",
    "            for _ in range(heads)\n",
    "        ])\n",
    "        self.out_att = GATLayer(hidden_features * heads, out_features, dropout=dropout, alpha=alpha, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = torch.cat([att(x, edge_index) for att in self.attentions], dim=1)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.out_att(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Train/Test Split ---------------------\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "num_nodes = data.num_nodes\n",
    "train_mask, test_mask = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "test_mask = torch.tensor(test_mask, dtype=torch.long)\n",
    "\n",
    "# --------------------- Training Setup ---------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GATNet(in_features=x.shape[1], hidden_features=8, out_features=2, heads=4).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 1.5443 | Test Accuracy: 0.4536\n",
      "Epoch 010 | Loss: 1.0208 | Test Accuracy: 0.5295\n",
      "Epoch 020 | Loss: 0.6928 | Test Accuracy: 0.6745\n",
      "Epoch 030 | Loss: 0.5462 | Test Accuracy: 0.8310\n",
      "Epoch 040 | Loss: 0.4674 | Test Accuracy: 0.8804\n",
      "Epoch 050 | Loss: 0.4182 | Test Accuracy: 0.8984\n",
      "Epoch 060 | Loss: 0.3861 | Test Accuracy: 0.9074\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Training Loop ---------------------\n",
    "for epoch in range(1, 70):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # model.eval()\n",
    "    # _, pred = out[test_mask].max(dim=1)\n",
    "    # correct = pred.eq(data.y[test_mask]).sum().item()\n",
    "    # acc = correct / test_mask.size(0)\n",
    "\n",
    "    # if epoch % 10 == 0 or epoch == 1:\n",
    "    #     print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = loss_fn(out[train_mask], data.y[train_mask])\n",
    "\n",
    "    # Predictions\n",
    "    log_probs = out[test_mask]\n",
    "    prob = log_probs.exp()  # [num_test_samples, num_classes]\n",
    "    _, pred = prob.max(dim=1)\n",
    "    correct = pred.eq(data.y[test_mask]).sum().item()\n",
    "    acc = correct / test_mask.size(0)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySSWXs8ov1MS",
    "outputId": "c63367df-296f-444c-a099-999e5cce5115"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.spatial import KDTree\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # --------------------- Load and Prepare Data ---------------------\n",
    "# df = pd.read_csv(\"preprocessed_mining_data.csv\")\n",
    "\n",
    "# # Define target (oil mine presence)\n",
    "# conditions = (\n",
    "#     (df['P Wave Velocity (km/s)'] < 4.5) &\n",
    "#     (df['S Wave Velocity (km/s)'] < 2.5) &\n",
    "#     (df['Carbon Emission (ppm)'] > 350) &\n",
    "#     (df['hrock_type'].isin([2, 3]))\n",
    "# )\n",
    "# df['oil_mine_presence'] = np.where(conditions, 1, 0)\n",
    "\n",
    "# # Encode categorical features\n",
    "# categorical_cols = ['hrock_type', 'arock_type', 'structure', 'orebody_fm']\n",
    "# label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "# for col in categorical_cols:\n",
    "#     df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "# # Feature selection\n",
    "# features = ['latitude', 'longitude', 'P Wave Velocity (km/s)', 'S Wave Velocity (km/s)',\n",
    "#             'Humidity (%)', 'Carbon Emission (ppm)', 'hrock_type', 'arock_type',\n",
    "#             'structure', 'orebody_fm']\n",
    "# df_features = df[features]\n",
    "# df_target = df['oil_mine_presence']\n",
    "\n",
    "# # Normalize features\n",
    "# scaler = StandardScaler()\n",
    "# df_features = pd.DataFrame(scaler.fit_transform(df_features), columns=features)\n",
    "# nodes_np = df_features.values\n",
    "# y = torch.tensor(df_target.values, dtype=torch.long)\n",
    "\n",
    "# # --------------------- Graph Construction ---------------------\n",
    "# tree = KDTree(nodes_np)\n",
    "# k = 10\n",
    "# distances, indices = tree.query(nodes_np, k=k)\n",
    "\n",
    "# edges = []\n",
    "# for i, neighbors in enumerate(indices):\n",
    "#     for j in neighbors:\n",
    "#         if i != j:\n",
    "#             edges.append((i, j))\n",
    "\n",
    "# # Convert edges to tensor format\n",
    "# edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "# x = torch.tensor(nodes_np, dtype=torch.float)\n",
    "\n",
    "# # --------------------- Custom GAT Layer ---------------------\n",
    "# class GATLayer(nn.Module):\n",
    "#     def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n",
    "#         super(GATLayer, self).__init__()\n",
    "#         self.dropout = dropout\n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.concat = concat\n",
    "\n",
    "#         self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "#         self.a = nn.Parameter(torch.empty(size=(2 * out_features, 1)))\n",
    "#         nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "#         nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "#         self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "#     def forward(self, h, edge_index):\n",
    "#         Wh = torch.mm(h, self.W)\n",
    "#         edge_h = torch.cat((Wh[edge_index[0]], Wh[edge_index[1]]), dim=1)\n",
    "#         e = self.leakyrelu(torch.matmul(edge_h, self.a).squeeze(1))\n",
    "\n",
    "#         # Normalize attention coefficients\n",
    "#         e = F.dropout(e, self.dropout, training=self.training)\n",
    "#         attention = torch.zeros(h.size(0), h.size(0), device=h.device)\n",
    "#         attention[edge_index[0], edge_index[1]] = e\n",
    "#         attention = F.softmax(attention, dim=1)\n",
    "\n",
    "#         h_prime = torch.matmul(attention, Wh)\n",
    "\n",
    "#         if self.concat:\n",
    "#             return F.elu(h_prime)\n",
    "#         else:\n",
    "#             return h_prime\n",
    "\n",
    "# # --------------------- GAT Model ---------------------\n",
    "# class GATNet(nn.Module):\n",
    "#     def __init__(self, in_features, hidden_features, out_features, dropout=0.6, alpha=0.2, heads=4):\n",
    "#         super(GATNet, self).__init__()\n",
    "#         self.dropout = dropout\n",
    "#         self.attentions = nn.ModuleList([\n",
    "#             GATLayer(in_features, hidden_features, dropout=dropout, alpha=alpha, concat=True)\n",
    "#             for _ in range(heads)\n",
    "#         ])\n",
    "#         self.out_att = GATLayer(hidden_features * heads, out_features, dropout=dropout, alpha=alpha, concat=False)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = F.dropout(x, self.dropout, training=self.training)\n",
    "#         x = torch.cat([att(x, edge_index) for att in self.attentions], dim=1)\n",
    "#         x = F.dropout(x, self.dropout, training=self.training)\n",
    "#         x = self.out_att(x, edge_index)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "# # --------------------- Train/Test Split ---------------------\n",
    "# data = Data(x=x, edge_index=edge_index, y=y)\n",
    "# num_nodes = data.num_nodes\n",
    "# train_mask, test_mask = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "# test_mask = torch.tensor(test_mask, dtype=torch.long)\n",
    "\n",
    "# # --------------------- Training Setup ---------------------\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = GATNet(in_features=x.shape[1], hidden_features=8, out_features=2, heads=4).to(device)\n",
    "# data = data.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "# loss_fn = nn.NLLLoss()\n",
    "\n",
    "# # --------------------- Training Loop ---------------------\n",
    "# for epoch in range(1, 70):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     out = model(data.x, data.edge_index)\n",
    "#     loss = loss_fn(out[train_mask], data.y[train_mask])\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     model.eval()\n",
    "#     _, pred = out[test_mask].max(dim=1)\n",
    "#     correct = pred.eq(data.y[test_mask]).sum().item()\n",
    "#     acc = correct / test_mask.size(0)\n",
    "\n",
    "#     if epoch % 10 == 0 or epoch == 1:\n",
    "#         print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize prediction columns\n",
    "df['predicted_oil_presence'] = np.nan\n",
    "df['prediction_probability'] = np.nan\n",
    "\n",
    "# Fill predictions for test set\n",
    "df.loc[test_mask.cpu().numpy(), 'predicted_oil_presence'] = pred.cpu().numpy()\n",
    "df.loc[test_mask.cpu().numpy(), 'prediction_probability'] = prob.max(dim=1).values.detach().cpu().numpy()\n",
    "\n",
    "# Save to CSV\n",
    "df[['latitude', 'longitude', 'predicted_oil_presence', 'prediction_probability']].to_csv(\"oil_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLQnVRBdOOFC",
    "outputId": "074a3482-e490-4414-db11-77948948603e"
   },
   "outputs": [],
   "source": [
    "# # --- Export Predictions ---\n",
    "# # df['predicted_oil_presence'] = pred.cpu().numpy()  # Ensure 'pred' is defined\n",
    "# # df['prediction_probability'] = prob.cpu().numpy()  # Ensure 'prob' is defined\n",
    "# # df[['latitude', 'longitude', 'predicted_oil_presence', 'prediction_probability']].to_csv(\"oil_predictions.csv\", index=False)\n",
    "# # --- Export Predictions ---\n",
    "# # Create a new column initialized to NaN\n",
    "# df['predicted_oil_presence'] = np.nan\n",
    "# df['prediction_probability'] = np.nan\n",
    "\n",
    "# # Assign predicted values and probabilities only to the test set\n",
    "# df.loc[test_mask.numpy(), 'predicted_oil_presence'] = pred.cpu().numpy()  # Ensure 'pred' is defined\n",
    "# df.loc[test_mask.numpy(), 'prediction_probability'] = prob.cpu().numpy()  # Ensure 'prob' is defined\n",
    "\n",
    "# # Save the relevant columns to CSV\n",
    "# df[['latitude', 'longitude', 'predicted_oil_presence', 'prediction_probability']].to_csv(\"oil_predictions.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7lhr_aUOinB"
   },
   "source": [
    "visualization attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label distribution: (array([0]), array([42155]))\n",
      "Predicted label distribution: (array([0, 1]), array([38486,  3669]))\n"
     ]
    }
   ],
   "source": [
    "print(\"True label distribution:\", np.unique(true, return_counts=True))\n",
    "print(\"Predicted label distribution:\", np.unique(pred, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oil_mine_presence\n",
      "0    210772\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['oil_mine_presence'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class 1 samples: 0\n"
     ]
    }
   ],
   "source": [
    "# How many class 1s do we even have?\n",
    "n_class_1 = (df['oil_mine_presence'] == 1).sum()\n",
    "print(f\"Number of class 1 samples: {n_class_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention visualization skipped to avoid memory overhead.\n",
      "Precision: 0.000\n",
      "Recall:    0.000\n",
      "F1-score:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user105/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Skip Attention Visualization (or make a safe dummy function) ---\n",
    "def visualize_attention(*args, **kwargs):\n",
    "    print(\"Attention visualization skipped to avoid memory overhead.\")\n",
    "\n",
    "# Call after model.eval():\n",
    "visualize_attention(None, node_index=5)\n",
    "\n",
    "# --- Validation Metrics ---\n",
    "true = y_test.cpu().numpy()\n",
    "pred = pred.cpu().numpy()\n",
    "\n",
    "precision = precision_score(true, pred)\n",
    "recall = recall_score(true, pred)\n",
    "f1 = f1_score(true, pred)\n",
    "\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "BCXpWLNSI6BF",
    "outputId": "f238a839-9d56-401c-d19e-c7a6cc81e528"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# # --- Visualize Attention Weights (assuming attention_scores is collected during forward pass) ---\n",
    "# def visualize_attention(attention_scores, node_index, top_k=10):\n",
    "#     # attention_scores: (num_edges, )\n",
    "#     # node_index: int - which node to visualize\n",
    "#     attention_scores = attention_scores.view(-1)\n",
    "#     neighbors = (edge_index[0] == node_index).nonzero(as_tuple=True)[0]\n",
    "#     values = attention_scores[neighbors].detach().cpu().numpy()\n",
    "#     neighbor_ids = edge_index[1][neighbors].cpu().numpy()\n",
    "\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     sns.barplot(x=neighbor_ids[:top_k], y=values[:top_k])\n",
    "#     plt.title(f\"Attention Weights for Node {node_index}\")\n",
    "#     plt.xlabel(\"Neighbor Node ID\")\n",
    "#     plt.ylabel(\"Attention Score\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Call after model.eval():\n",
    "# visualize_attention(attention_weights, node_index=5)\n",
    "\n",
    "# # --- Validation Metrics ---\n",
    "# true = y_test.cpu().numpy()\n",
    "# pred = pred.cpu().numpy()\n",
    "\n",
    "# precision = precision_score(true, pred)\n",
    "# recall = recall_score(true, pred)\n",
    "# f1 = f1_score(true, pred)\n",
    "\n",
    "# print(f\"Precision: {precision:.3f}\")\n",
    "# print(f\"Recall:    {recall:.3f}\")\n",
    "# print(f\"F1-score:  {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "veKivI8cjAzm",
    "outputId": "4c4d5c0d-2fe8-437b-d6eb-ee72b90de11e"
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# --------------------- Evaluation and Prediction ---------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "\n",
    "# Original labels and predictions\n",
    "true_labels = data.y.cpu().numpy()\n",
    "pred_labels = pred.cpu().numpy()\n",
    "\n",
    "# Get lat/lon for test data\n",
    "# Convert test_mask to actual indices\n",
    "test_indices = test_mask.nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "\n",
    "# Create a test DataFrame using these indices\n",
    "df_test = df.iloc[test_indices].copy()\n",
    "\n",
    "# Add true and predicted labels for these test samples\n",
    "df_test[\"true_label\"] = true_labels[test_mask.cpu().numpy()]\n",
    "df_test[\"pred_label\"] = pred_labels[test_mask.cpu().numpy()]\n",
    "\n",
    "# df_test = df.iloc[test_mask.cpu().numpy()]\n",
    "# df_test = df_test.copy()\n",
    "# df_test[\"true_label\"] = true_labels[test_mask.cpu().numpy()]\n",
    "# df_test[\"pred_label\"] = pred_labels[test_mask.cpu().numpy()]\n",
    "\n",
    "# --------------------- Folium Map ---------------------\n",
    "map_center = [df[\"latitude\"].mean(), df[\"longitude\"].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=6)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Plot all actual oil mines in test set\n",
    "for _, row in df_test[df_test[\"true_label\"] == 1].iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=4,\n",
    "        color=\"green\",\n",
    "        fill=True,\n",
    "        fill_color=\"green\",\n",
    "        popup=\"Actual Oil Mine\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Plot predicted oil mines not originally labeled (false positives)\n",
    "for _, row in df_test[(df_test[\"true_label\"] == 0) & (df_test[\"pred_label\"] == 1)].iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=6,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_color=\"red\",\n",
    "        popup=\"Predicted Oil Mine\"\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Save or display the map\n",
    "m.save(\"predicted_oil_mines_map.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "PmQbBSKnlJzf",
    "outputId": "a5265e5c-974f-433f-baf6-fd4d00cfbe67"
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Filter test predictions where predicted != true\n",
    "false_predictions = df_test[df_test[\"true_label\"] != df_test[\"pred_label\"]]\n",
    "\n",
    "# Debug: Check if we have any\n",
    "print(\"Number of incorrect predictions:\", len(false_predictions))\n",
    "print(false_predictions[['latitude', 'longitude', 'true_label', 'pred_label']].head())\n",
    "\n",
    "# Optional: Use mean center of all false predictions\n",
    "if not false_predictions.empty:\n",
    "    map_center = [false_predictions[\"latitude\"].mean(), false_predictions[\"longitude\"].mean()]\n",
    "else:\n",
    "    map_center = [0, 0]  # Fallback center if no predictions\n",
    "\n",
    "# Create map\n",
    "m = folium.Map(location=map_center, zoom_start=2)\n",
    "\n",
    "# Add markers\n",
    "for _, row in false_predictions.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_color=\"red\",\n",
    "        popup=f'True: {row[\"true_label\"]}, Pred: {row[\"pred_label\"]}',\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display map in notebook\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "6WhIzA5TlicD",
    "outputId": "a8debc1b-ee55-453d-cb72-b03fc208c9f1"
   },
   "outputs": [],
   "source": [
    "# Use all test nodes, not just incorrect ones\n",
    "all_predictions = df_test.copy()\n",
    "\n",
    "m = folium.Map(location=[all_predictions[\"latitude\"].mean(), all_predictions[\"longitude\"].mean()], zoom_start=3)\n",
    "\n",
    "for _, row in all_predictions.iterrows():\n",
    "    color = \"green\" if row[\"true_label\"] == row[\"pred_label\"] else \"red\"\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=4,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        fill_color=color,\n",
    "        popup=f'True: {row[\"true_label\"]}, Pred: {row[\"pred_label\"]}',\n",
    "    ).add_to(m)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "yabEac46lpVR",
    "outputId": "07765a0f-1a9c-4cbc-accb-1d09dba7a31f"
   },
   "outputs": [],
   "source": [
    "sample = df_test.sample(n=10)  # Adjust 'n' based on your data\n",
    "\n",
    "m = folium.Map(location=[sample[\"latitude\"].mean(), sample[\"longitude\"].mean()], zoom_start=3)\n",
    "\n",
    "for _, row in sample.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        popup=f'True: {row[\"true_label\"]}, Pred: {row[\"pred_label\"]}',\n",
    "        icon=folium.Icon(color='blue')\n",
    "    ).add_to(m)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjpRm4ecmp59"
   },
   "source": [
    "Below is a complete code block that:\n",
    "\n",
    "Loads your new test.csv.\n",
    "\n",
    "Preprocesses it (assuming it has latitude, longitude, and a label column).\n",
    "\n",
    "Feeds it into your trained model.\n",
    "\n",
    "Compares predictions to true labels.\n",
    "\n",
    "Plots the results on a Folium map, highlighting:\n",
    "\n",
    "Correct predictions in green\n",
    "\n",
    "Incorrect predictions in red\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CHodYFaiM5x"
   },
   "source": [
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "6VIXmG1Mmr2k",
    "outputId": "50851f6f-c1ad-4c39-b816-62f81da236ac"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import folium\n",
    "\n",
    "# Load test data (no labels expected)\n",
    "df_test = pd.read_csv(\"preprocessed_mining_data.csv\")\n",
    "\n",
    "# Feature columns (drop lat/lon)\n",
    "feature_cols = df_test.columns.difference([\"latitude\", \"longitude\"])\n",
    "x_test = torch.tensor(df_test[feature_cols].values, dtype=torch.float)\n",
    "\n",
    "# Build PyG Data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_data = Data(x=x_test).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(test_data.x)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df_test[\"predicted_oil_mine\"] = pred\n",
    "\n",
    "# Map\n",
    "center_lat = df_test[\"latitude\"].mean()\n",
    "center_lon = df_test[\"longitude\"].mean()\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=4)\n",
    "\n",
    "# Visualize predictions\n",
    "for _, row in df_test.iterrows():\n",
    "    color = \"green\" if row[\"predicted_oil_mine\"] == 1 else \"gray\"\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Prediction: {'Oil Mine' if row['predicted_oil_mine'] == 1 else 'No Mine'}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m.save(\"predicted_test_map.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "cJHTbA92o5WB",
    "outputId": "1b4a6da6-bdb0-4221-f822-057fca14ab8b"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "import folium\n",
    "\n",
    "# --- Step 1: Align test features with training ---\n",
    "test_features = df_test[features]  # Use same feature list as training\n",
    "test_scaled = scaler.transform(test_features)  # Reuse training scaler\n",
    "x_test = torch.tensor(test_scaled, dtype=torch.float).to(device)\n",
    "\n",
    "# --- Step 2: Build graph (KDTree) ---\n",
    "tree = KDTree(test_scaled)\n",
    "_, indices = tree.query(test_scaled, k=10)\n",
    "\n",
    "edges = []\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for j in neighbors:\n",
    "        if i != j:\n",
    "            edges.append((i, j))\n",
    "\n",
    "test_edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(device)\n",
    "\n",
    "# --- Step 3: Run inference ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(x_test, test_edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# --- Step 4: Add predictions to DataFrame ---\n",
    "df_test[\"predicted_oil_mine\"] = pred\n",
    "\n",
    "# --- Step 5: Visualize on Folium map ---\n",
    "m = folium.Map(location=[df_test[\"latitude\"].mean(), df_test[\"longitude\"].mean()], zoom_start=5)\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    color = \"green\" if row[\"predicted_oil_mine\"] == 1 else \"gray\"\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Prediction: {'Oil Mine' if row['predicted_oil_mine'] == 1 else 'No Mine'}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m.save(\"predicted_test_map.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "bfqFmN1AoEeo",
    "outputId": "cdd8c68e-141e-4f75-b815-0d745e98e010"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "import folium\n",
    "\n",
    "# Build new edge_index for test set\n",
    "tree = KDTree(x_test.numpy())\n",
    "_, indices = tree.query(x_test.numpy(), k=10)\n",
    "\n",
    "edges = []\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for j in neighbors:\n",
    "        if i != j:\n",
    "            edges.append((i, j))\n",
    "test_edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(device)\n",
    "\n",
    "# Run prediction\n",
    "model.eval()\n",
    "test_data = Data(x=x_test.to(device))\n",
    "with torch.no_grad():\n",
    "    out = model(test_data.x, test_edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "df_test[\"predicted_oil_mine\"] = pred\n",
    "\n",
    "# Create Folium map\n",
    "m = folium.Map(location=[df_test[\"latitude\"].mean(), df_test[\"longitude\"].mean()], zoom_start=5)\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    color = \"green\" if row[\"predicted_oil_mine\"] == 1 else \"gray\"\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Prediction: {'Oil Mine' if row['predicted_oil_mine'] == 1 else 'No Mine'}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m.save(\"predicted_test_map.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH43vfbmhzTe"
   },
   "outputs": [],
   "source": [
    "# # Train/val/test split\n",
    "# X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "#     x, y, np.arange(x.size(0)), test_size=0.2, stratify=y, random_state=42\n",
    "# )\n",
    "# X_train, X_val, y_train, y_val, train_idx, val_idx = train_test_split(\n",
    "#     X_train, y_train, train_idx, test_size=0.2, stratify=y_train, random_state=42\n",
    "# )\n",
    "\n",
    "# # Convert to tensor indices\n",
    "# train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "# val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "# test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "# train_mask[train_idx] = True\n",
    "# val_mask[val_idx] = True\n",
    "# test_mask[test_idx] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tRVogyOh253",
    "outputId": "b6c707da-6c2c-4385-9d3c-70ab4f35d44c"
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GATNet(in_features=x.shape[1], hidden_features=8, out_features=2).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# x, edge_index, y = x.to(device), edge_index.to(device), y.to(device)\n",
    "# train_mask, val_mask, test_mask = train_mask.to(device), val_mask.to(device), test_mask.to(device)\n",
    "\n",
    "# # Training loop\n",
    "# def train():\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     out = model(x, edge_index)\n",
    "#     loss = F.nll_loss(out[train_mask], y[train_mask])\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     return loss.item()\n",
    "\n",
    "# # Evaluation\n",
    "# def evaluate(mask):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         out = model(x, edge_index)\n",
    "#         pred = out[mask].argmax(dim=1)\n",
    "#         acc = (pred == y[mask]).sum().item() / mask.sum().item()\n",
    "#     return acc\n",
    "\n",
    "# # Run training\n",
    "# for epoch in range(1, 201):\n",
    "#     loss = train()\n",
    "#     val_acc = evaluate(val_mask)\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f\"Epoch {epoch}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# # Test accuracy\n",
    "# test_acc = evaluate(test_mask)\n",
    "# print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 928
    },
    "id": "0JfV5LgMKuDo",
    "outputId": "f6518fae-c468-4526-abb6-1ce67227e0aa"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from torch.utils.data import DataLoader\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# from scipy.spatial import KDTree\n",
    "\n",
    "# # Load data\n",
    "# df = pd.read_csv(\"preprocessed_mining_data.csv\")\n",
    "\n",
    "# # Define conditions for oil presence\n",
    "# oil_conditions = (\n",
    "#     (df['P Wave Velocity (km/s)'] < 5.5) &\n",
    "#     (df['S Wave Velocity (km/s)'] < 3.5) &\n",
    "#     (df['Carbon Emission (ppm)'] > 350) &\n",
    "#     (df['hrock_type'].isin([1, 2, 3]))\n",
    "# )\n",
    "# df['oil_mine_presence'] = np.where(oil_conditions, 1, 0)\n",
    "# print(df['oil_mine_presence'].value_counts())\n",
    "\n",
    "# # Encode categorical columns\n",
    "# categorical_cols = ['hrock_type', 'arock_type', 'structure', 'orebody_fm']\n",
    "# label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "# for col in categorical_cols:\n",
    "#     df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "# # Feature columns\n",
    "# features = ['latitude', 'longitude', 'P Wave Velocity (km/s)', 'S Wave Velocity (km/s)',\n",
    "#             'Humidity (%)', 'Carbon Emission (ppm)', 'hrock_type', 'arock_type',\n",
    "#             'structure', 'orebody_fm']\n",
    "\n",
    "# df_features = df[features]\n",
    "# df_target = df['oil_mine_presence']\n",
    "\n",
    "# # Normalize features\n",
    "# scaler = StandardScaler()\n",
    "# df_features = pd.DataFrame(scaler.fit_transform(df_features), columns=features)\n",
    "# nodes = df_features.values\n",
    "\n",
    "# # Build KDTree for edge construction\n",
    "# tree = KDTree(nodes)\n",
    "# k = 10\n",
    "# distances, indices = tree.query(nodes, k=k)\n",
    "\n",
    "# # Build edge index\n",
    "# graph_edges = []\n",
    "# for src, neighbors in enumerate(indices):\n",
    "#     for dst in neighbors:\n",
    "#         if src != dst:\n",
    "#             graph_edges.append([src, dst])\n",
    "# edge_index = torch.tensor(graph_edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# # Convert to PyTorch tensors\n",
    "# x = torch.tensor(nodes, dtype=torch.float)\n",
    "# y = torch.tensor(df_target.values, dtype=torch.long)\n",
    "\n",
    "# # Split train/test\n",
    "# X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(x, y, np.arange(len(y)), test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define GAT Layer\n",
    "# class GATLayer(nn.Module):\n",
    "#     def __init__(self, in_features, out_features):\n",
    "#         super(GATLayer, self).__init__()\n",
    "#         self.W = nn.Linear(in_features, out_features, bias=False)\n",
    "#         self.a = nn.Parameter(torch.zeros(size=(2 * out_features, 1)))\n",
    "#         nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         h = self.W(x)\n",
    "#         N = h.size(0)\n",
    "\n",
    "#         src, dst = edge_index\n",
    "#         a_input = torch.cat([h[src], h[dst]], dim=1)\n",
    "#         e = F.leaky_relu(torch.matmul(a_input, self.a).squeeze())\n",
    "\n",
    "#         attention = torch.zeros(N, N)\n",
    "#         attention[src, dst] = e\n",
    "#         attention = F.softmax(attention, dim=1)\n",
    "#         h_prime = torch.matmul(attention, h)\n",
    "\n",
    "#         return h_prime, attention.detach()\n",
    "\n",
    "# # Model class\n",
    "# class GAT(nn.Module):\n",
    "#     def __init__(self, in_features, hidden_features, out_features):\n",
    "#         super(GAT, self).__init__()\n",
    "#         self.gat1 = GATLayer(in_features, hidden_features)\n",
    "#         self.out = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x, attn_weights = self.gat1(x, edge_index)\n",
    "#         x = F.elu(x)\n",
    "#         x = self.out(x)\n",
    "#         return x, attn_weights\n",
    "\n",
    "# # Initialize model\n",
    "# model = GAT(x.size(1), 8, 2)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Training loop\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     out, _ = model(x, edge_index)\n",
    "#     loss = criterion(out[idx_train], y[idx_train])\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if (epoch+1) % 10 == 0:\n",
    "#         print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# # Evaluate\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     out, attention_weights = model(x, edge_index)\n",
    "#     preds = out.argmax(dim=1)\n",
    "#     y_true = y[idx_test].cpu().numpy()\n",
    "#     y_pred = preds[idx_test].cpu().numpy()\n",
    "\n",
    "#     precision = precision_score(y_true, y_pred)\n",
    "#     recall = recall_score(y_true, y_pred)\n",
    "#     f1 = f1_score(y_true, y_pred)\n",
    "#     print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "#     # Export predictions\n",
    "#     pred_df = pd.DataFrame({\n",
    "#         \"Index\": idx_test,\n",
    "#         \"True Label\": y_true,\n",
    "#         \"Predicted Label\": y_pred\n",
    "#     })\n",
    "#     pred_df.to_csv(\"gat_predictions.csv\", index=False)\n",
    "\n",
    "#     # Visualize attention weights for a few nodes\n",
    "#     attn_np = attention_weights.numpy()\n",
    "#     avg_attention = attn_np.mean(axis=0)\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.heatmap(attn_np[:50, :50], cmap=\"viridis\")\n",
    "#     plt.title(\"Attention Weights (First 50 Nodes)\")\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
